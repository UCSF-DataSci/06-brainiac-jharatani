{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55fa0ac4",
   "metadata": {},
   "source": [
    "# Assignment 6: Neural Network Showdown\n",
    "\n",
    "Build and compare neural network architectures on image and time-series data.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ebeae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt\n",
    "\n",
    "# GPU acceleration (platform-specific)\n",
    "import platform\n",
    "if platform.system() == \"Darwin\" and platform.machine() == \"arm64\":\n",
    "    %pip install -q tensorflow-metal\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed70f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected — using CPU\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Report available accelerators\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU acceleration: {len(gpus)} device(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  {gpu.name}\")\n",
    "else:\n",
    "    print(\"No GPU detected — using CPU\")\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import (\n",
    "    Dense, Flatten, Dropout, Conv2D, MaxPooling2D, LSTM, Input\n",
    ")\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from helpers import (\n",
    "    load_cifar10, load_ecg5000,\n",
    "    plot_training_history, plot_confusion_matrix,\n",
    "    plot_sample_images, plot_ecg_traces, plot_predictions,\n",
    "    CIFAR10_CLASSES, ECG_CLASSES,\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f79d00",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Dense Baseline on CIFAR-10\n",
    "\n",
    "**Task:** Build a Dense (fully connected) network to classify CIFAR-10 images.\n",
    "\n",
    "CIFAR-10 has 60,000 color images (32x32x3) across 10 classes. A Dense network\n",
    "flattens each image into 3,072 numbers and classifies from there. This is our\n",
    "baseline — it ignores spatial structure entirely.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- Flatten the input\n",
    "- At least 2 hidden Dense layers with ReLU activation\n",
    "- Dropout after each hidden layer\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e592393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Dense Baseline on CIFAR-10\n",
      "----------------------------------------\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jharatani/06-brainiac-jharatani/.venv/lib/python3.12/site-packages/keras/src/datasets/cifar.py:18: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  d = cPickle.load(f, encoding=\"bytes\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (50000, 32, 32, 3), Test: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1: Dense Baseline on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load data (normalized to [0,1], one-hot encoded)\n",
    "X_train, y_train, X_test, y_test = load_cifar10()\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training images to verify data loaded correctly\n",
    "plot_sample_images(X_train, y_train, CIFAR10_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc56b343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">786,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m786,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">820,874</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m820,874\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">820,874</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m820,874\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Build a Dense model using Sequential\n",
    "# Tip: call model_dense.summary() after building to verify your architecture\n",
    "# Requirements:\n",
    "#   - Input(shape=(32, 32, 3))\n",
    "#   - Flatten()\n",
    "#   - At least 2 Dense hidden layers with activation='relu'\n",
    "#   - Dropout after each hidden Dense layer\n",
    "#   - Dense(10, activation='softmax') as output\n",
    "\n",
    "model_dense = Sequential([\n",
    "    Input(shape=(32, 32, 3)),\n",
    "    Flatten(),                              # 32x32x3 = 3,072 inputs\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='softmax') # 10 class probabilities\n",
    "])\n",
    "\n",
    "model_dense.summary()  # replace with your Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52067ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "model_dense.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333c3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.2211 - loss: 2.0934 - val_accuracy: 0.3176 - val_loss: 1.9020\n",
      "Epoch 2/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2783 - loss: 1.9466 - val_accuracy: 0.3464 - val_loss: 1.8450\n",
      "Epoch 3/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3004 - loss: 1.9048 - val_accuracy: 0.3578 - val_loss: 1.8128\n",
      "Epoch 4/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3133 - loss: 1.8743 - val_accuracy: 0.3608 - val_loss: 1.7992\n",
      "Epoch 5/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3237 - loss: 1.8487 - val_accuracy: 0.3790 - val_loss: 1.7709\n",
      "Epoch 6/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3255 - loss: 1.8414 - val_accuracy: 0.3730 - val_loss: 1.7622\n",
      "Epoch 7/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3334 - loss: 1.8229 - val_accuracy: 0.3724 - val_loss: 1.7649\n",
      "Epoch 8/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3364 - loss: 1.8181 - val_accuracy: 0.3882 - val_loss: 1.7364\n",
      "Epoch 9/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3417 - loss: 1.8021 - val_accuracy: 0.3978 - val_loss: 1.7234\n",
      "Epoch 10/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3447 - loss: 1.7920 - val_accuracy: 0.4026 - val_loss: 1.7236\n",
      "Epoch 11/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3458 - loss: 1.7871 - val_accuracy: 0.3994 - val_loss: 1.7289\n",
      "Epoch 12/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3501 - loss: 1.7811 - val_accuracy: 0.3992 - val_loss: 1.7016\n",
      "Epoch 13/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3519 - loss: 1.7744 - val_accuracy: 0.3864 - val_loss: 1.7286\n",
      "Epoch 14/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3532 - loss: 1.7743 - val_accuracy: 0.4098 - val_loss: 1.7002\n",
      "Epoch 15/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3527 - loss: 1.7637 - val_accuracy: 0.4074 - val_loss: 1.6989\n",
      "Epoch 16/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3581 - loss: 1.7566 - val_accuracy: 0.4002 - val_loss: 1.6928\n",
      "Epoch 17/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3568 - loss: 1.7583 - val_accuracy: 0.4142 - val_loss: 1.6874\n",
      "Epoch 18/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3590 - loss: 1.7574 - val_accuracy: 0.4126 - val_loss: 1.6852\n",
      "Epoch 19/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3567 - loss: 1.7553 - val_accuracy: 0.4130 - val_loss: 1.6895\n",
      "Epoch 20/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3676 - loss: 1.7403 - val_accuracy: 0.3854 - val_loss: 1.7103\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train with EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3,\n",
    "                            restore_best_weights=True)\n",
    "history_dense = model_dense.fit(X_train, y_train,\n",
    "                                 epochs=20, batch_size=128,\n",
    "                                 validation_split=0.1,\n",
    "                                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65f71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "test_loss, test_acc = model_dense.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "y_pred = np.argmax(model_dense.predict(X_test, verbose=0), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6de654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jharatani/06-brainiac-jharatani/helpers.py:242: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Optional: visualize predictions and confusion matrix to diagnose issues\n",
    "plot_predictions(X_test, y_true, y_pred, CIFAR10_CLASSES)\n",
    "plot_confusion_matrix(y_true, y_pred, list(CIFAR10_CLASSES.values()),\n",
    "                       os.path.join(OUTPUT_DIR, \"part1_confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b65a99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense accuracy: 0.4135\n",
      "Saved output/part1_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results = {\n",
    "    \"accuracy\": float(test_acc),\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part1_results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(\"Saved output/part1_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4daa2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: CNN on CIFAR-10\n",
    "\n",
    "**Task:** Build a CNN to classify the same CIFAR-10 images. Compare its accuracy\n",
    "to the Dense baseline from Part 1.\n",
    "\n",
    "CNNs use convolutional filters that slide across the image, detecting local\n",
    "patterns (edges, textures, shapes). This preserves spatial structure that\n",
    "Dense layers discard.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- At least 2 Conv2D + MaxPooling2D blocks\n",
    "- Flatten, then Dense hidden layer with Dropout\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a124f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPart 2: CNN on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Data is already loaded from Part 1 (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a CNN model using Sequential\n",
    "# Requirements:\n",
    "#   - Input(shape=(32, 32, 3))\n",
    "#   - At least 2 blocks of: Conv2D(filters, (3,3), activation='relu')\n",
    "#                            + MaxPooling2D((2,2))\n",
    "#   - Flatten()\n",
    "#   - Dense hidden layer with ReLU + Dropout\n",
    "#   - Dense(10, activation='softmax') as output\n",
    "# Tip: call model_cnn.summary() after building to check layer shapes and param counts\n",
    "model_cnn = None  # replace with your Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model_cnn.compile(optimizer='adam',\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train with EarlyStopping and ModelCheckpoint\n",
    "# callbacks = [\n",
    "#     EarlyStopping(monitor='val_loss', patience=3,\n",
    "#                   restore_best_weights=True),\n",
    "#     ModelCheckpoint('output/best_cnn.keras',\n",
    "#                     save_best_only=True, monitor='val_accuracy'),\n",
    "# ]\n",
    "# history_cnn = model_cnn.fit(X_train, y_train,\n",
    "#                             epochs=15, batch_size=64,\n",
    "#                             validation_split=0.1,\n",
    "#                             callbacks=callbacks)\n",
    "history_cnn = None  # replace with your fit call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd07834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "# plot_training_history(history_cnn,\n",
    "#                       os.path.join(OUTPUT_DIR, \"part2_training_history.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# cnn_loss, cnn_acc = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "cnn_acc = None  # replace\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred_cnn = np.argmax(model_cnn.predict(X_test, verbose=0), axis=1)\n",
    "# y_true_cnn = np.argmax(y_test, axis=1)\n",
    "# cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)\n",
    "y_pred_cnn = None  # replace\n",
    "y_true_cnn = None  # replace\n",
    "cm_cnn = None  # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d455628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize predictions and confusion matrix to diagnose issues\n",
    "# plot_predictions(X_test, y_true_cnn, y_pred_cnn, CIFAR10_CLASSES)\n",
    "# plot_confusion_matrix(y_true_cnn, y_pred_cnn, list(CIFAR10_CLASSES.values()),\n",
    "#                       os.path.join(OUTPUT_DIR, \"part2_confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_cnn = {\n",
    "    \"accuracy\": float(cnn_acc),\n",
    "    \"confusion_matrix\": cm_cnn.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part2_results.json\"), \"w\") as f:\n",
    "    json.dump(results_cnn, f, indent=2)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\"model\": \"Dense\", \"accuracy\": float(test_acc)},\n",
    "    {\"model\": \"CNN\", \"accuracy\": float(cnn_acc)},\n",
    "])\n",
    "comparison.to_csv(os.path.join(OUTPUT_DIR, \"part2_comparison.csv\"), index=False)\n",
    "\n",
    "print(f\"CNN accuracy:   {cnn_acc:.4f}\")\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(f\"Improvement:    {cnn_acc - test_acc:+.4f}\")\n",
    "print(\"Saved output/part2_results.json and output/part2_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f949ce7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: LSTM on ECG5000\n",
    "\n",
    "**Task:** Build an LSTM to classify heartbeat recordings.\n",
    "\n",
    "ECG5000 contains 5,000 heartbeat recordings — each is 140 time steps of voltage\n",
    "measurements, classified into 5 types (Normal, Supraventricular, Premature\n",
    "Ventricular, Fusion, Unknown). This is sequential data where order matters,\n",
    "making it a natural fit for recurrent networks.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- LSTM layer (any reasonable number of units)\n",
    "- Dropout for regularization\n",
    "- Dense output with softmax (5 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPart 3: LSTM on ECG5000\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load ECG data (already shaped for RNN input)\n",
    "X_train_ecg, y_train_ecg, X_test_ecg, y_test_ecg = load_ecg5000()\n",
    "print(f\"Train: {X_train_ecg.shape}, Test: {X_test_ecg.shape}\")\n",
    "print(f\"Classes: {list(ECG_CLASSES.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ECG traces to understand the data\n",
    "plot_ecg_traces(X_train_ecg, y_train_ecg, ECG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789dec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build an LSTM model using Sequential\n",
    "# Requirements:\n",
    "#   - Input(shape=(140, 1))\n",
    "#   - LSTM layer (e.g., 64 units)\n",
    "#   - Dropout\n",
    "#   - Dense(5, activation='softmax')\n",
    "# Tip: call model_lstm.summary() after building to verify your architecture\n",
    "model_lstm = None  # replace with your Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model_lstm.compile(optimizer='adam',\n",
    "#                    loss='categorical_crossentropy',\n",
    "#                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train with EarlyStopping\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5,\n",
    "#                            restore_best_weights=True)\n",
    "# history_lstm = model_lstm.fit(X_train_ecg, y_train_ecg,\n",
    "#                               epochs=30, batch_size=32,\n",
    "#                               validation_split=0.1,\n",
    "#                               callbacks=[early_stop])\n",
    "history_lstm = None  # replace with your fit call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "# plot_training_history(history_lstm,\n",
    "#                       os.path.join(OUTPUT_DIR, \"part3_training_history.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b28180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# lstm_loss, lstm_acc = model_lstm.evaluate(X_test_ecg, y_test_ecg, verbose=0)\n",
    "lstm_acc = None  # replace\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred_ecg = np.argmax(model_lstm.predict(X_test_ecg, verbose=0), axis=1)\n",
    "# y_true_ecg = np.argmax(y_test_ecg, axis=1)\n",
    "# cm_ecg = confusion_matrix(y_true_ecg, y_pred_ecg)\n",
    "y_pred_ecg = None  # replace\n",
    "y_true_ecg = None  # replace\n",
    "cm_ecg = None  # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize confusion matrix to see which heartbeat types are confused\n",
    "# plot_confusion_matrix(y_true_ecg, y_pred_ecg, list(ECG_CLASSES.values()),\n",
    "#                       os.path.join(OUTPUT_DIR, \"part3_confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_ecg = {\n",
    "    \"accuracy\": float(lstm_acc),\n",
    "    \"confusion_matrix\": cm_ecg.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part3_results.json\"), \"w\") as f:\n",
    "    json.dump(results_ecg, f, indent=2)\n",
    "\n",
    "print(f\"LSTM accuracy: {lstm_acc:.4f}\")\n",
    "print(\"Saved output/part3_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69849039",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00802a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAll parts complete!\")\n",
    "print(\"Run 'pytest .github/tests/ -v' in your terminal to check your work.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
